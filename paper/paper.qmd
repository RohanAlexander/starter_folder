---
title: "US President Prediction"
subtitle: "Predict the results of 2024 US President Election"
author: 
  - Yun Chu
  - Felix Li
  - Wen Han Zhao 
thanks: "Code and data are available at: [https://github.com/younazhao/US-President-Prediction/tree/main](https://github.com/younazhao/US-President-Prediction/tree/main)."
date: 22 October 2024
date-format: long
abstract: "In this study, we aim to study the 2024 U.S. Presidential Election with the methodology of  polls of polls across various states. With the insightful analyses on polls provided by Redfiled & Wilton Strategies, the conducted survey on the population highlights various key point for the prediction of US president. Using Generalized Linear Models (GLMs), this report analyzes the accuracy of prediction in president votes through several key variables from pollster. The model incorporates variables such as pollscore, methodology, transparency_score and hypothetical. The prediction finding highlights the significance of candicate trustworthiness among the voter decision, providing insights for swing voters. This analysis offers valuable information into the potential electoral outcomes driving the 2024 US president election. "
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
library(tidyverse)
library(knitr)
library(kableExtra)
library(readr)
library(dplyr)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data.... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.



# Model {#set-model}

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix @sec-model-details].

## Model set-up

Define $y_i$ as the percentage of support for a candicate in a poll.

${y_i} = \beta_0 + \beta_1 pollscore + \beta_2 methodology + \beta_3transparency score + \beta_4 hypothetical + \epsilon$ 

pollscore: A numeric value representing the score or reliability of the pollster in question (e.g., -1.1). "The error and bias we can attribute to a pollster. Negative numbers are better. Stands for "Predictive Optimization of Latent skill Level in Surveys, Considering Overall Record, Empirically.

methodology: The method used to conduct the poll (e.g., Online Panel).

transparency_score: A score reflecting the pollsterâ€™s transparency about their methodology (e.g., 9.0). "A grade for how transparent a pollster is, calculated based on how much information it discloses about its polls and weighted by 
by recency. The highest Transparency Score is 10."
 
hypothetical: Indicates whether the poll is about a hypothetical match-up.

We run the model in R [@citeR].


### Model justification

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Library setup
#install.packages("glm")
library(glmnet)
library(ggplot2)
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-model1
#| tbl-cap: "model 1"
#| warning: false
# Get the analysis data
analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

# Model
glm_model1 <- glm(pct ~ pollscore + methodology + transparency_score + hypothetical, data = analysis_data, family = gaussian()) 

# Get the summary
model_summary <- summary(glm_model1)

# Convert the summary coefficients to a data frame
summary_table <- as.data.frame(model_summary$coefficients)

# Create a table with a caption and control the size
kable(summary_table, caption = "Model 1 Summary Table", size = "small")
```

## Lasso Regularization {#sec-model-lassoregularization}
Lasso Regularization is performed to see if the selected variable in our model would best predict the results of polls percentage of a candidate. If the variable do not align with our actual numbers, we should consider other variables or a interaction variable. 

```{r}
#| echo: false
#| eval: true
#| label: tbl-lassoregularization
#| tbl-cap: "lasso regularization"
#| warning: false
# Prepare the predictors
x <- model.matrix(pct ~ pollscore + methodology + transparency_score + hypothetical, data = analysis_data)[, -1]

# Prepare the response variable
y <- analysis_data$pct

# Lasso regression (alpha = 1)
lasso_model <- glmnet(x, y, alpha = 1, family = "gaussian")

# Cross-validation for Lasso
cv_lasso <- cv.glmnet(x, y, alpha = 1, family = "gaussian")

plot(cv_lasso)

# Get the best lambda
best_lambda_lasso <- cv_lasso$lambda.min

# Refit Lasso with the optimal lambda
lasso_final_model <- glmnet(x, y, alpha = 1, lambda = best_lambda_lasso, family = "gaussian")

# View Lasso coefficients
coef.lasso <- coef(lasso_final_model)

# Predict using Lasso
pred_lasso <- predict(lasso_final_model, s = best_lambda_lasso, newx = x)

```


Computing the Mean Square Error would give us a sense of our lasso model prediction. 
```{r}
#| echo: false
#| eval: true
#| label: tbl-msr
#| tbl-cap: "Mean Squared Error"
#| warning: false
# Calculate Mean Squared Error
mse <- mean((y - pred_lasso)^2)
cat("Mean Squared Error:", mse, "\n")

# Calculate R-squared
sst <- sum((y - mean(y))^2)
sse <- sum((y - pred_lasso)^2)
r_squared <- 1 - (sse / sst)
cat("R-squared:", r_squared, "\n")

# Create a data frame for plotting
results_df <- data.frame(
  Metric = c("SST", "SSE", "R-squared"),
  Value = c(sst, sse, r_squared)
)

kable(results_df, caption = "Mean Squared Error Table")
```


From this graph, we can see that the cluster points do not perfectly align on the line of the best fit so we should still investigate in other variables. 
```{r}
#| echo: false
#| eval: true
#| label: tbl-actualvspredicted
#| tbl-cap: "actual vs predicted"
#| warning: false

# Compare predicted vs actual values
comparison <- data.frame(Actual = y, Predicted = as.vector(pred_lasso))

kable(head(comparison), caption = "Actual vs Predicted")

# Plot actual vs predicted values
ggplot(comparison, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Actual vs Predicted Values",
       x = "Actual Values",
       y = "Predicted Values") +
  theme_minimal()
```


\newpage

\appendix

# Appendix {-}


# Additional data details

## pollster methodology analysis

This survey was conducted by Redfield & Wilton Strategies to assess the voting intentions of eligible voters in key U.S. swing states ahead of the 2024 Presidential Election. The primary goal of this poll is to provide an accurate and timely snapshot of public opinion in states where electoral outcomes are uncertain and could have a decisive impact on the overall result of the election. Swing states, due to their political volatility and diverse voter bases, are critical in determining the balance of power in the U.S. electoral system. Understanding voter preferences in these states is essential for political analysts, campaigns, and the general public.

### Population of Interest
The population of interest for this survey consists of all eligible voters residing in major U.S. swing states, specifically Arizona, Florida, Georgia, Michigan, North Carolina, and Pennsylvania. These states are known for their fluctuating political alignments and are expected to play a crucial role in the upcoming election.

### Sampling Frame
The population sampled includes eligible voters from Arizona, Florida, Georgia, Michigan, North Carolina, and Pennsylvania. Participants were selected via an online panel.

### Sample
The sample sizes for each state were as follows:

Arizona: 750 respondents

Florida: 1,350 respondents

Georgia: 927 respondents

Michigan: 970 respondents

North Carolina: 880 respondents

Pennsylvania: 1,070 respondents

## Weakness & Strength of the methodology

In terms of strengths, Redfield & Wilton has a great reputation for producing reliable polling data. They have employ a mix of online and telephone survey, which add in various resources of collecting their data. This approach can help reduce bias. In addition, Redfield & Wilton often target swing states, which makes their polls results important to the US president election.

The weakness of their methodology would incorporate a certain potential bias based on their political leaning of their clients or media. This could cause a certain neutrality in their dataset. 

Overall, Redfield & Wilton has been considered as a competent, reputable and reliable pollster with his variaty and methodology on polls. Even though the pollster contained a potential bias, it has been a reliable resource in prediction of US president election. 


# Model details {#sec-model-details}



\newpage


# References


